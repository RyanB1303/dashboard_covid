{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "[COMPLETE]\n",
    "\n",
    "Our data comes directly from the [John Hopkins COVID-19 Github repository][1], which tracks all deaths and cases from each country in the world as well as many regions within some countries. All of the data needed for this project is within the [time series][2] directory, which contains four CSV files that summarize the deaths and cases for the world and the USA. The repository uses the word \"confirmed\" to refer to cases.\n",
    "\n",
    "[1]: https://github.com/CSSEGISandData/COVID-19\n",
    "[2]: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into a pandas DataFrame\n",
    "\n",
    "The pandas `read_csv` function can read in remote CSV files by passing it the URL. The exact URL on Github is a bit tricky. You must use the \"raw\" data file, which can be retrieved by clicking on the file name (taking you to the next page), then right-clicking the \"view raw\" or \"download\" button and copying the link. The image below shows the screen you'll see for the first CSV.\n",
    "\n",
    "![1]\n",
    "\n",
    "[1]: images/url_download.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "\n",
    "Before we write any code, let's cover some naming conventions that we will use throughout the project.\n",
    "\n",
    "### `group`\n",
    "\n",
    "We will use the name `group` to refer to the two separate \"groups\" of data.\n",
    "\n",
    "* `\"world\"` - represents all data from each country\n",
    "* `\"usa\"` - represents all data from each US state\n",
    "\n",
    "### `kind`\n",
    "\n",
    "We will use the name `kind` to refer to the two different kinds of COVID-19 data.\n",
    "\n",
    "* `\"deaths\"`\n",
    "* `\"cases\"`\n",
    "\n",
    "\n",
    "### `area`\n",
    "\n",
    "Occasionally, we will refer to either a specific country or state with the name `area`.\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "Now that we have the URL, we can download the data with pandas. Complete the exercise below to download all four files as DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in a single CSV and returns it as a DataFrame. This function accepts a kind and group. Use the variable `DOWNLOAD_URL` in your solution. Make sure you look at the URL in the repo from above to determine what values `kind` and `group` refer to. You'll have to reassign their values in the function so that the URL is correct. For example, the function call `download_data(\"world\", \"deaths\")` should download [one of the files on this page](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_URL = (\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/\"\n",
    "    \"master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "    \"time_series_covid19_{kind}_{group}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "def download_data(group, kind):\n",
    "    \"\"\"\n",
    "    Reads in a single dataset from the John Hopkins GitHub repo\n",
    "    as a DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    group_dict = {\"world\": \"global\", \"usa\": \"US\"}\n",
    "    kind_dict = {\"deaths\": \"deaths\", \"cases\": \"confirmed\"}\n",
    "    return pd.read_csv(DOWNLOAD_URL.format(group=group_dict[group], kind=kind_dict[kind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information on exercises - please read!\n",
    "\n",
    "All of the exercises require you to complete the body of a function. All functions end with the `pass` keyword. **Delete** it and write your solution in the body of the function.\n",
    "\n",
    "Solutions for all exercises are found in the [solutions.py](solutions.py) file in this directory. You can open it up in your favorite editor, or just click the link to open it in your browser.\n",
    "\n",
    "In the code cell following each exercise, you will see a single line of code that imports the function from the solutions.py file. For example, `from solutions import download_data`. Running this statement will provide you with a version of the function that produces the correct output for the exercise.\n",
    "\n",
    "**Comment out the import line** if you want to use and test **your version** of the function completed above. I highly recommend completing the exercises on your own. Keep the import line uncommented if you do not attempt the exercise. \n",
    "\n",
    "**Always check the solutions!** Make sure to check the [solutions.py](solutions.py) file for each exercise, even if you are sure you answered it correctly. Verifying solutions is one of the best known methods for internalizing new material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the `download_data` function\n",
    "\n",
    "Let's read in the world deaths file as a DataFrame and output the head to verify that it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>11/4/21</th>\n",
       "      <th>11/5/21</th>\n",
       "      <th>11/6/21</th>\n",
       "      <th>11/7/21</th>\n",
       "      <th>11/8/21</th>\n",
       "      <th>11/9/21</th>\n",
       "      <th>11/10/21</th>\n",
       "      <th>11/11/21</th>\n",
       "      <th>11/12/21</th>\n",
       "      <th>11/13/21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7284</td>\n",
       "      <td>7284</td>\n",
       "      <td>7284</td>\n",
       "      <td>7284</td>\n",
       "      <td>7288</td>\n",
       "      <td>7290</td>\n",
       "      <td>7291</td>\n",
       "      <td>7292</td>\n",
       "      <td>7292</td>\n",
       "      <td>7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2944</td>\n",
       "      <td>2948</td>\n",
       "      <td>2948</td>\n",
       "      <td>2955</td>\n",
       "      <td>2966</td>\n",
       "      <td>2970</td>\n",
       "      <td>2975</td>\n",
       "      <td>2978</td>\n",
       "      <td>2983</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5936</td>\n",
       "      <td>5939</td>\n",
       "      <td>5941</td>\n",
       "      <td>5945</td>\n",
       "      <td>5950</td>\n",
       "      <td>5954</td>\n",
       "      <td>5960</td>\n",
       "      <td>5966</td>\n",
       "      <td>5971</td>\n",
       "      <td>5977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1718</td>\n",
       "      <td>1719</td>\n",
       "      <td>1719</td>\n",
       "      <td>1720</td>\n",
       "      <td>1721</td>\n",
       "      <td>1723</td>\n",
       "      <td>1723</td>\n",
       "      <td>1725</td>\n",
       "      <td>1726</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  11/4/21  11/5/21  11/6/21  \\\n",
       "0        0        0        0        0  ...     7284     7284     7284   \n",
       "1        0        0        0        0  ...     2944     2948     2948   \n",
       "2        0        0        0        0  ...     5936     5939     5941   \n",
       "3        0        0        0        0  ...      130      130      130   \n",
       "4        0        0        0        0  ...     1718     1719     1719   \n",
       "\n",
       "   11/7/21  11/8/21  11/9/21  11/10/21  11/11/21  11/12/21  11/13/21  \n",
       "0     7284     7288     7290      7291      7292      7292      7292  \n",
       "1     2955     2966     2970      2975      2978      2983      2986  \n",
       "2     5945     5950     5954      5960      5966      5971      5977  \n",
       "3      130      130      130       130       130       130       130  \n",
       "4     1720     1721     1723      1723      1725      1726      1727  \n",
       "\n",
       "[5 rows x 666 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment out the import line below if you attempted the exercise above\n",
    "# keep the line below if you did not attempt the exercise\n",
    "#from solutions import download_data \n",
    "df_world_deaths = download_data('world', 'deaths')\n",
    "df_world_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a another function which uses `download_data` to read in all four DataFrames.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in all four CSVs as DataFrames returning them in a dictionary. Use the group and kind separated by an underscore as the key (i.e. `\"world_deaths\"`). Use the `GROUPS` and `KINDS` variables in your solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = \"world\", \"usa\"\n",
    "KINDS = \"deaths\", \"cases\"\n",
    "\n",
    "def read_all_data():\n",
    "    \"\"\"\n",
    "    Read in all four CSVs as DataFrames\n",
    "    0. how to read the GROUPS 1\n",
    "    1. make download_data to all cases and deaths kinds to world and usa groups\n",
    "    2. arrange them in dictionary\n",
    "    3. return it\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    world_deaths = download_data(GROUPS[0], KINDS[0])\n",
    "    world_cases = download_data(GROUPS[0], KINDS[1])\n",
    "    usa_deaths = download_data(GROUPS[1], KINDS[0])\n",
    "    usa_cases = download_data(GROUPS[1], KINDS[1])\n",
    "    return {\"world_deaths\": world_deaths,\n",
    "            \"world_cases\": world_cases,\n",
    "            \"usa_deaths\": usa_deaths,\n",
    "            \"usa_cases\": usa_cases\n",
    "           }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to read in all of the data and output the head of two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to comment out the following line if you attempt the exercise\n",
    "# this is the last exercise with this warning\n",
    "#from solutions import read_all_data\n",
    "data = read_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['world_cases'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['world_deaths'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['usa_deaths'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>11/4/21</th>\n",
       "      <th>11/5/21</th>\n",
       "      <th>11/6/21</th>\n",
       "      <th>11/7/21</th>\n",
       "      <th>11/8/21</th>\n",
       "      <th>11/9/21</th>\n",
       "      <th>11/10/21</th>\n",
       "      <th>11/11/21</th>\n",
       "      <th>11/12/21</th>\n",
       "      <th>11/13/21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>10304</td>\n",
       "      <td>10314</td>\n",
       "      <td>10327</td>\n",
       "      <td>10331</td>\n",
       "      <td>10335</td>\n",
       "      <td>10350</td>\n",
       "      <td>10355</td>\n",
       "      <td>10373</td>\n",
       "      <td>10383</td>\n",
       "      <td>10401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>37495</td>\n",
       "      <td>37529</td>\n",
       "      <td>37633</td>\n",
       "      <td>37648</td>\n",
       "      <td>37659</td>\n",
       "      <td>37737</td>\n",
       "      <td>37745</td>\n",
       "      <td>37785</td>\n",
       "      <td>37819</td>\n",
       "      <td>37855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>3609</td>\n",
       "      <td>3611</td>\n",
       "      <td>3612</td>\n",
       "      <td>3614</td>\n",
       "      <td>3614</td>\n",
       "      <td>3620</td>\n",
       "      <td>3622</td>\n",
       "      <td>3631</td>\n",
       "      <td>3632</td>\n",
       "      <td>3648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 11/4/21  11/5/21  11/6/21  11/7/21  11/8/21  \\\n",
       "0  32.539527 -86.644082  ...   10304    10314    10327    10331    10335   \n",
       "1  30.727750 -87.722071  ...   37495    37529    37633    37648    37659   \n",
       "2  31.868263 -85.387129  ...    3609     3611     3612     3614     3614   \n",
       "\n",
       "   11/9/21  11/10/21  11/11/21  11/12/21  11/13/21  \n",
       "0    10350     10355     10373     10383     10401  \n",
       "1    37737     37745     37785     37819     37855  \n",
       "2     3620      3622      3631      3632      3648  \n",
       "\n",
       "[3 rows x 673 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['usa_cases'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data locally\n",
    "\n",
    "Since the raw data must be downloaded from the internet, let's save a copy of our current data to a local folder so that we have access to it immediately at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that accepts a dictionary of DataFrames and a directory name, and writes them to that directory as CSVs using the key as the filename. Pass the `kwargs` to the `to_csv` method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, directory, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes each raw data DataFrame to a file as a CSV\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dictionary of DataFrames\n",
    "\n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    kwargs : extra keyword arguments for the `to_csv` DataFrame method\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for judul, dataframe in data.items():\n",
    "        dataframe.to_csv(directory + \"/\" + judul + \".csv\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write those DataFrames as CSVs (without their index) to the \"data/raw\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from solutions import write_data\n",
    "write_data(data, \"data/raw\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `download_data`, but have it read in the local data that we just saved. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_local_data(group, kind, directory):\n",
    "    \"\"\"\n",
    "    Read in one CSV as a DataFrame from the given directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(directory + \"/\" + group + \"_\" + kind + \".csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>11/4/21</th>\n",
       "      <th>11/5/21</th>\n",
       "      <th>11/6/21</th>\n",
       "      <th>11/7/21</th>\n",
       "      <th>11/8/21</th>\n",
       "      <th>11/9/21</th>\n",
       "      <th>11/10/21</th>\n",
       "      <th>11/11/21</th>\n",
       "      <th>11/12/21</th>\n",
       "      <th>11/13/21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7284</td>\n",
       "      <td>7284</td>\n",
       "      <td>7284</td>\n",
       "      <td>7284</td>\n",
       "      <td>7288</td>\n",
       "      <td>7290</td>\n",
       "      <td>7291</td>\n",
       "      <td>7292</td>\n",
       "      <td>7292</td>\n",
       "      <td>7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2944</td>\n",
       "      <td>2948</td>\n",
       "      <td>2948</td>\n",
       "      <td>2955</td>\n",
       "      <td>2966</td>\n",
       "      <td>2970</td>\n",
       "      <td>2975</td>\n",
       "      <td>2978</td>\n",
       "      <td>2983</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5936</td>\n",
       "      <td>5939</td>\n",
       "      <td>5941</td>\n",
       "      <td>5945</td>\n",
       "      <td>5950</td>\n",
       "      <td>5954</td>\n",
       "      <td>5960</td>\n",
       "      <td>5966</td>\n",
       "      <td>5971</td>\n",
       "      <td>5977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  11/4/21  11/5/21  11/6/21  \\\n",
       "0        0        0        0        0  ...     7284     7284     7284   \n",
       "1        0        0        0        0  ...     2944     2948     2948   \n",
       "2        0        0        0        0  ...     5936     5939     5941   \n",
       "\n",
       "   11/7/21  11/8/21  11/9/21  11/10/21  11/11/21  11/12/21  11/13/21  \n",
       "0     7284     7288     7290      7291      7292      7292      7292  \n",
       "1     2955     2966     2970      2975      2978      2983      2986  \n",
       "2     5945     5950     5954      5960      5966      5971      5977  \n",
       "\n",
       "[3 rows x 666 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from solutions import read_local_data\n",
    "read_local_data('world', 'deaths', 'data/raw').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `read_all_data`, but have it read in all of the local data that we just saved. The function name is `run` since we will be slowly adding all of our data cleaning and transformation steps to it in the next chapter.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "    Run all cleaning and transformation steps\n",
    "    \n",
    "    GROUPS = \"world\", \"usa\"\n",
    "    KINDS = \"deaths\", \"cases\"\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for group in GROUPS:\n",
    "        for kind in KINDS:\n",
    "            df = read_local_data(group, kind, 'data/raw')\n",
    "            data[f\"{group}_{kind}\"] = df\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we verify that `run` works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>11/4/21</th>\n",
       "      <th>11/5/21</th>\n",
       "      <th>11/6/21</th>\n",
       "      <th>11/7/21</th>\n",
       "      <th>11/8/21</th>\n",
       "      <th>11/9/21</th>\n",
       "      <th>11/10/21</th>\n",
       "      <th>11/11/21</th>\n",
       "      <th>11/12/21</th>\n",
       "      <th>11/13/21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>84090056</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90056.0</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>84056043</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.904516</td>\n",
       "      <td>-107.680187</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>84056045</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.839612</td>\n",
       "      <td>-104.567488</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 674 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           UID iso2 iso3  code3     FIPS      Admin2 Province_State  \\\n",
       "3339  84090056   US  USA    840  90056.0  Unassigned        Wyoming   \n",
       "3340  84056043   US  USA    840  56043.0    Washakie        Wyoming   \n",
       "3341  84056045   US  USA    840  56045.0      Weston        Wyoming   \n",
       "\n",
       "     Country_Region        Lat       Long_  ... 11/4/21  11/5/21  11/6/21  \\\n",
       "3339             US   0.000000    0.000000  ...       0        0        0   \n",
       "3340             US  43.904516 -107.680187  ...      35       35       35   \n",
       "3341             US  43.839612 -104.567488  ...       9        9        9   \n",
       "\n",
       "      11/7/21  11/8/21  11/9/21  11/10/21  11/11/21  11/12/21  11/13/21  \n",
       "3339        0        0        0         0         0         0         0  \n",
       "3340       35       35       35        35        35        35        35  \n",
       "3341        9        9       10        10        10        10        10  \n",
       "\n",
       "[3 rows x 674 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from solutions import run\n",
    "data = run()\n",
    "data['usa_deaths'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the section on downloading the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
